# 2.2. Data Manipulation with Pandas

## Introduction to Pandas

Pandas is a powerful and popular open-source Python library for data manipulation and analysis. It provides high-performance, easy-to-use data structures, and data analysis tools. The name "Pandas" is derived from "Panel Data," an econometrics term for multidimensional, structured data sets.

Pandas is a cornerstone of data science in Python, offering two primary data structures that are fundamental to data manipulation: the `Series` and the `DataFrame`.

## Pandas Data Structures: Series

A **Series** is a one-dimensional labeled array capable of holding any data type (integers, strings, floating-point numbers, Python objects, etc.). It is similar to a column in a spreadsheet or a single column from a database table.

**Example: Creating a Series**

To create a Series, you can pass a list of values to the `pd.Series()` constructor.

```python
import pandas as pd

# Creating a Series from a list
data = [2,-1,3,5]
s = pd.Series(data)
print(s)
```

**Output:**

```
0    2
1   -1
2    3
3    5
dtype: int64
```

`Series` objects behave much like one-dimensional NumPy `ndarray`s, and you can often pass them as parameters to NumPy functions:
```python
import numpy as np
np.exp(s)
```

**Output:**

```
0      7.389056
1      0.367879
2     20.085537
3    148.413159
dtype: float64
```

Arithmetic operations on `Series` are also possible, and they apply *elementwise*, just like for `ndarray`s:
```python
s + [1000,2000,3000,4000]
```

**Output:**

```
0    1002
1    1999
2    3003
3    4005
dtype: int64
```

Similar to NumPy, if you add a single number to a `Series`, that number is added to all items in the `Series`. This is called *broadcasting*:

```python
s + 1000
```

**Output:**

```
0    1002
1     999
2    1003
3    1005
dtype: int64
```

The same is true for all binary operations such as `*` or `/`, and even conditional operations:

```python
s < 0
```

**Output:**

```
0    False
1     True
2    False
3    False
dtype: bool
```

### Index
By default, index is simply the rank of the item in the `Series` (starting from `0`) but you can also set the index labels manually:

```python
s2 = pd.Series(
    [68, 83, 112, 68], 
    index=["alice", "bob", "charles", "darwin"]
)
s2
```

**Output:**

```
alice       68
bob         83
charles    112
darwin      68
dtype: int64
```

> **Note:** If you initialize a `Series` with a scalar value and a list of indices, the scalar value is repeated for each index.
>
> ```python
> pd.Series(42, ["life", "universe", "everything"])
> ```
>
> **Output:**
>
> ```
> life          42
> universe      42
> everything    42
> dtype: int64
> ```

You can then use the `Series` just like a `dict`:

```python
s2["bob"]
```

**Output:**

```
83
```

You can also use the `Series` as a dictionary to set values:

```python
s2["bob"] = 100
print(s2)
```

To make it clear when you are accessing by label or by integer location, it is recommended to always use the `loc` attribute when accessing by label, and the `iloc` attribute when accessing by integer location:

```python
s2.loc["bob"]
```

**Output:**

```
83
```

```python
s2.iloc[1]
```

**Output:**

```
83
```
Slicing a Series is similar to slicing a list:

```python
s2.iloc[1:3]
```

**Output:**

```
bob         83
charles    112
dtype: int64
```

### Alternative Constructor

You can also create a `Series` from a dictionary:

```python
weights = {"alice": 68, "bob": 83, "colin": 86, "darwin": 68}
s3 = pd.Series(weights)
s3
```

**Output:**

```
alice     68
bob       83
colin     86
darwin    68
dtype: int64
```

### Automatic Alignment

When you perform arithmetic operations on `Series`, the operations are performed element-wise, and the indices of the `Series` are automatically aligned.

```python
s3 + s2
```

**Output:**

```
alice      136.0
bob        166.0
charles      NaN
colin        NaN
darwin     136.0
dtype: float64
```

> **Note:** NaN stands for "Not a Number" and is used to represent missing values.

### Name of the Series

You can also set the name of the `Series` using the `name` parameter:

```python
s6 = pd.Series([83, 68], index=["bob", "alice"], name="weights")
s6
```

**Output:**

```
bob      83
alice    68
Name: weights, dtype: int64
```

## Pandas Data Structures: DataFrame

A **DataFrame** is a two-dimensional labeled data structure with columns of potentially different types. It is similar to a spreadsheet, a SQL table, or a dictionary of Series objects. It is the most commonly used pandas object.

## Creating a DataFrame

You can create a DataFrame from a dictionary of lists, where each list represents a column.

```python
import pandas as pd

# Creating a DataFrame from a dictionary
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 30, 35, 40],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']
}
df = pd.DataFrame(data)
print(df)
```

**Output:**

```
      Name  Age         City
0    Alice   25     New York
1      Bob   30  Los Angeles
2  Charlie   35      Chicago
3    David   40      Houston
```

You can also create a DataFrame from a dictionary of `Series` objects:

```python
weight_series = pd.Series([68, 83, 112], index=["alice", "bob", "charles"])
birthyear_series = pd.Series([1984, 1985, 1992], index=["bob", "alice", "charles"], name="year")
children_series = pd.Series([0, 3], index=["charles", "bob"])
hobby_series = pd.Series(["Biking", "Dancing"], index=["alice", "bob"])

people_dict = {
    "weight": weight_series,
    "birthyear": birthyear_series,
    "children": children_series,
    "hobby": hobby_series,
}
people = pd.DataFrame(people_dict)
people
```

**Output:**

```
         weight  birthyear  children    hobby
alice        68       1985       NaN   Biking
bob          83       1984       3.0  Dancing
charles     112       1992       0.0      NaN
```

> **Note:** The `Series` were automatically aligned based on the indices and the missing values are represented as `NaN`. Also note that the name `year` was dropped from the `birthyear` `Series`.

You can access columns using the `[]` operator. They are returned as `Series` objects:

```python
people["birthyear"]
```

**Output:**

```
alice      1985
bob        1984
charles    1992
Name: birthyear, dtype: int64
```

You can also get multiple columns at once:
```python
people[["birthyear", "hobby"]]
```

**Output:**

```
         birthyear    hobby
alice       1985   Biking
bob         1984  Dancing
charles     1992      NaN
dtype: object
```

If you pass a list of columns and/or index row labels to the `DataFrame` constructor.

```python
d2 = pd.DataFrame(
        people_dict,
        columns=["birthyear", "weight", "height"], # reorder the columns
        index=["bob", "alice", "eugene"] # reorder the index
     )
d2
```
**Output:**

```
        birthyear  weight height
bob        1984.0    83.0    NaN
alice      1985.0    68.0    NaN
eugene        NaN     NaN    NaN
```

### Alternative Constructors

Another convenient way to create a `DataFrame` is to pass all the values to the constructor as an `ndarray`, or a list of lists, and specify the column names and row index labels separately:

```python
values = [
            [1985, np.nan, "Biking",   68],
            [1984, 3,      "Dancing",  83],
            [1992, 0,      np.nan,    112]
         ]
d3 = pd.DataFrame(
        values,
        columns=["birthyear", "children", "hobby", "weight"],
        index=["alice", "bob", "charles"]
     )
d3
```

**Output:**

```
         birthyear  children    hobby  weight
alice         1985       NaN   Biking      68
bob           1984       3.0  Dancing      83
charles       1992       0.0      NaN     112
```

It is also possible to create a `DataFrame` with a dictionary (or list) of dictionaries (or lists):

```python
people = pd.DataFrame({
    "birthyear": {"alice": 1985, "bob": 1984, "charles": 1992},
    "hobby": {"alice": "Biking", "bob": "Dancing"},
    "weight": {"alice": 68, "bob": 83, "charles": 112},
    "children": {"bob": 3, "charles": 0}
})
people
```

**Output:**

```
         birthyear    hobby  weight  children
alice         1985   Biking      68       NaN
bob           1984  Dancing      83       3.0
charles       1992      NaN     112       0.0
```

### Multi-Index DataFrame
<!-- TODO: Add content here -->

### Dropping Levels
<!-- TODO: Add content here -->

## Date/Time Manipulation

Pandas has a rich set of tools for working with dates and times, which is essential for time series analysis.

### Time Series Basics

Pandas represents dates and times using the `datetime64` dtype. The `to_datetime()` function can be used to convert strings or other formats to `datetime` objects.

**Example: Creating a date range**

```python
# Create a range of dates
dates = pd.to_datetime(['2023-01-01', '2023-01-02', '2023-01-03'])

# Create a DataFrame with a time series index
ts = pd.Series(np.random.randn(len(dates)), index=dates)
print(ts)
```

**Example: Accessing date components**

Once you have a `datetime` object, you can access its components like year, month, and day.

```python
print(ts.index.year)
print(ts.index.month)
print(ts.index.day)
```

## Data Transformation

Data transformation is the process of converting data from one format or structure to another. It is a fundamental aspect of most data integration and data management tasks, such as data wrangling and data warehousing.

### Aggregating and Grouping Data

Grouping and aggregating data is a common task in data analysis. The `groupby()` method is used to split the data into groups based on some criteria, and then you can apply an aggregate function (like `sum`, `mean`, `count`, etc.) to each group.

**Example: Grouping by city and calculating the mean salary**

```python
# Group by the 'City' column and calculate the mean of the other columns
city_groups = df.groupby('City').mean()
print(city_groups)
```

### Merging, Joining, and Concatenating DataFrames

Pandas provides various facilities for easily combining together Series or DataFrame objects.

- **`concat()`**: Appends one or more DataFrames.
- **`merge()`**: Joins two DataFrames in a database-style join.

**Example: Concatenating two DataFrames**

```python
df1 = pd.DataFrame({'A': ['A0', 'A1'], 'B': ['B0', 'B1']})
df2 = pd.DataFrame({'A': ['A2', 'A3'], 'B': ['B2', 'B3']})

result = pd.concat([df1, df2])
print(result)
```

**Example: Merging two DataFrames**

```python
left = pd.DataFrame({'key': ['K0', 'K1'], 'A': ['A0', 'A1']})
right = pd.DataFrame({'key': ['K0', 'K1'], 'B': ['B0', 'B1']})

result = pd.merge(left, right, on='key')
print(result)
```

## Data Cleaning and Preparation

Data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.

Let's create a new DataFrame for this section with some missing values and duplicates:

```python
import pandas as pd
import numpy as np

data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Alice', 'Eva'],
    'Age': [25, 30, 35, 40, 25, 23],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'New York', 'Boston'],
    'Salary': [50000, 60000, 70000, 80000, 50000, np.nan]
}
df = pd.DataFrame(data)
```

### Handling Missing Data

Missing data is a common problem in real-world datasets. Pandas provides several methods to handle missing data, which are represented as `NaN` (Not a Number).

**Example: Checking for missing data**

```python
# isnull() returns a DataFrame of booleans indicating if a value is missing
print(df.isnull())

# isnull().sum() gives the count of missing values in each column
print(df.isnull().sum())
```

**Example: Dropping missing data**

```python
# Drop rows with any missing values
df_dropped = df.dropna()
print(df_dropped)
```

**Example: Filling missing data**

```python
# Fill missing salary with the mean salary
mean_salary = df['Salary'].mean()
df_filled = df.fillna({'Salary': mean_salary})
print(df_filled)
```

### Handling Duplicated Data

Duplicate rows can skew analysis. Pandas provides easy ways to find and remove them.

**Example: Identifying duplicate rows**

```python
# The duplicated() method returns a boolean Series indicating duplicate rows
print(df.duplicated())
```

**Example: Dropping duplicate rows**

```python
# The drop_duplicates() method removes duplicate rows
df_no_duplicates = df.drop_duplicates()
print(df_no_duplicates)
```

### Data Type Conversions

Sometimes data is not in the correct format. You can use the `astype()` method to convert data types.

**Example: Converting the 'Age' column to float**

```python
df['Age'] = df['Age'].astype(float)
print(df.dtypes)
```

## Indexing and Selecting Data

Pandas provides powerful methods for indexing and selecting data from a DataFrame. The primary methods are `loc` for label-based indexing and `iloc` for integer-based indexing.

Let's use the following DataFrame for the examples in this section:

```python
import pandas as pd

data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David'],
    'Age': [25, 30, 35, 40],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']
}
df = pd.DataFrame(data)
```

### `loc` and `iloc`

- **`loc`**: Access a group of rows and columns by label(s) or a boolean array.
- **`iloc`**: Purely integer-location based indexing for selection by position.

**Example: Selecting a single row with `loc`**

```python
# Select the row with index 1
print(df.loc[1])
```

**Output:**

```
Name              Bob
Age                30
City    Los Angeles
Name: 1, dtype: object
```

**Example: Selecting a single row with `iloc`**

```python
# Select the second row (index 1)
print(df.iloc[1])
```

**Output:**

```
Name              Bob
Age                30
City    Los Angeles
Name: 1, dtype: object
```

**Example: Selecting multiple rows and a single column**

```python
# Select the 'Name' column for the first two rows
print(df.loc[0:1, 'Name'])
```

**Output:**

```
0    Alice
1      Bob
Name: Name, dtype: object
```

### Conditional Selection

You can also select data based on a condition. This is a very common and powerful technique.

**Example: Selecting rows where Age is greater than 30**

```python
# Select rows where the 'Age' column is greater than 30
print(df[df['Age'] > 30])
```

**Output:**

```
      Name  Age     City
2  Charlie   35  Chicago
3    David   40  Houston
```

## Reading and Writing Data

Pandas provides a rich set of functions for reading data from various file formats and writing data back to them. The most common formats include CSV, Excel, JSON, and SQL databases.

**Example: Reading a CSV file**

Let's assume you have a CSV file named `data.csv` with the following content:

```csv
Name,Age,City
Alice,25,New York
Bob,30,Los Angeles
Charlie,35,Chicago
David,40,Houston
```

You can read this file into a DataFrame using `pd.read_csv()`:

```python
import pandas as pd

df = pd.read_csv('data.csv')
print(df)
```

**Example: Writing to a CSV file**

You can write a DataFrame to a CSV file using the `to_csv()` method.

```python
df.to_csv('output.csv', index=False)
```

The `index=False` argument prevents pandas from writing the DataFrame index as a column in the CSV file.