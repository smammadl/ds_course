# 2.2. Data Manipulation with Pandas

## Accessing Rows and Columns

Assuming we have the following `DataFrame`:

```python
people
```

**Output**
```
         weight  birthyear  children    hobby
alice        68       1985       NaN   Biking
bob          83       1984       3.0  Dancing
charles     112       1992       0.0      NaN
```

The columns can be accessed using the `[]` operator.
```python
people["birthyear"]
```
**Output:**
```
alice      1985
bob        1984
charles    1992
Name: birthyear, dtype: int64
```

> **Note**: Equivalently, you can access the columns using attribute-style notation.
> ```python
> people.birthyear
> ```
> **Output:**
> ```
> alice      1985
> bob        1984
> charles    1992
> Name: birthyear, dtype: int64
> ```
> Although this is more convenient, it is not as flexible as the `[]` operator and shouldn't be used for column assignment.

The `loc` attribute lets you access rows instead of columns. The result is a `Series` object in which the `DataFrame`'s column names are mapped to row index labels:

```python
people.iloc[2]
```

**Output**
```
birthyear    1992
hobby         NaN
weight        112
children      0.0
Name: charles, dtype: object
```

The primary methods are `loc` for label-based indexing and `iloc` for integer-based indexing. 

### `loc` and `iloc`

- **`loc`**: Access a group of rows and columns by label(s) or a boolean array.
- **`iloc`**: Purely integer-location based indexing for selection by position.

You can also get a slice of rows, and this returns a `DataFrame` object:
```python
people.iloc[1:3]
```
**
**Output:**
```
         weight  birthyear  children    hobby
bob          83       1984       3.0  Dancing
charles     112       1992       0.0      NaN
```

Using `iloc` and `loc` indexer we can slice the rows and columns of a `DataFrame`.

```python
people.iloc[:3, :2]
```

**Output:**
```
         birthyear    hobby
alice         1985   Biking
bob           1984  Dancing
charles       1992      NaN
```

```python
people.loc[:'bob', 'birthyear']
```

**Output:**
```
       birthyear
alice       1985
bob         1984
```

```python
people.loc[:'bob', 'birthyear':'weight']
```

**Output:**
```
       birthyear    hobby  weight
alice       1985   Biking      68
bob         1984  Dancing      83
```


```python
people[people["birthyear"] < 1990]
```

**Output:**
```
       weight  birthyear  children    hobby
alice      68       1985       NaN   Biking
bob        83       1984       3.0  Dancing
```

The mask can also be used with `loc` indexer.
```python
people.loc[people["birthyear"] < 1990, ["birthyear", "hobby"]]
```

**Output:**
```
       birthyear    hobby
alice       1985   Biking
bob         1984  Dancing
```

### Adding and Removing Columns

```python
people["age"] = 2018 - people["birthyear"]  # adds a new column "age"
people["over 30"] = people["age"] > 30      # adds another column "over 30"
birthyears = people.pop("birthyear")
del people["children"]
people.drop(['children'], axis='columns')

people
```

**Output:**
```
         weight    hobby  age  over 30
alice        68   Biking   33     True
bob          83  Dancing   34     True
charles     112      NaN   26    False
```

When you add a new column, it must have the same number of rows. Missing rows are filled with NaN, and extra rows are ignored:
```python
people["pets"] = pd.Series({"bob": 0, "charles": 5, "eugene": 1})  # alice is missing, eugene is ignored
people
```

**Output:**
```
         weight    hobby  age  over 30  pets
alice        68   Biking   33     True   NaN
bob          83  Dancing   34     True   0.0
charles     112      NaN   26    False   5.0
```

<!-- When adding a new column, it is added at the end (on the right) by default. You can also insert a column anywhere else using the `insert()` method:

```python
people.insert(1, "height", [172, 181, 185])
people
```

**Output:**
```
         weight  height    hobby  age  over 30  pets
alice        68     172   Biking   33     True   NaN
bob          83     181  Dancing   34     True   0.0
charles     112     185      NaN   26    False   5.0
``` 

### Adding New Columns
You can also create new columns by calling the `assign()` method. Note that this returns a new `DataFrame` object, the original is not modified:

```python
people.assign(
    body_mass_index = people["weight"] / (people["height"] / 100) ** 2,
    has_pets = people["pets"] > 0
)
```

**Output:**
```
         weight  height    hobby  age  over 30  pets  body_mass_index  \
alice        68     172   Biking   33     True   NaN        22.985398   
bob          83     181  Dancing   34     True   0.0        25.335002   
charles     112     185      NaN   26    False   5.0        32.724617   

         has_pets  
alice       False  
bob         False  
charles      True  
```

You can use chains of `assign()` with lambda functions to create new columns.
```python
(people
     .assign(body_mass_index = lambda df: df["weight"] / (df["height"] / 100) ** 2)
     .assign(overweight = lambda df: df["body_mass_index"] > 25)
)
```
**Output:**
```
         weight  height    hobby  age  over 30  pets  body_mass_index  \
alice        68     172   Biking   33     True   NaN        22.985398   
bob          83     181  Dancing   34     True   0.0        25.335002   
charles     112     185      NaN   26    False   5.0        32.724617   

         overweight  
alice         False  
bob            True  
charles        True 
```

### Evaluating an expression

A great feature supported by pandas is expression evaluation. It relies on the `numexpr` library which must be installed.
```python
people.eval("weight / (height/100) ** 2 > 25")
```

**Output:**
```
alice     False
bob        True
charles    True
dtype: bool
```

You can use the `eval()` method to evaluate an expression and assign the result to a new column.
```python
people.eval("body_mass_index = weight / (height/100) ** 2", inplace=True)
people
``` -->

## Sorting a `DataFrame`
You can sort a `DataFrame` by calling its `sort_index` method. By default, it sorts the rows by their index label, in ascending order, but let's reverse the order:

```python
people.sort_index(ascending=False)
```

**Output:**
```
         weight  birthyear  children    hobby
charles     112       1992       0.0      NaN
bob          83       1984       3.0  Dancing
alice        68       1985       NaN   Biking
```

Note that `sort_index` returned a sorted *copy* of the `DataFrame`. To modify `people` directly, we can set the `inplace` argument to `True`. Also, we can sort the columns instead of the rows by setting `axis=1`:

```python
people.sort_index(axis=1, inplace=True)
people
```

**Output:**
```
         birthyear  children    hobby  weight
alice       1985       NaN   Biking      68
bob         1984       3.0  Dancing      83
charles     1992       0.0      NaN     112
```

To sort the `DataFrame` by the values instead of the labels, we can use `sort_values` and specify the column to sort by:
```python
people.sort_values(by="weight", inplace=True)
people
```

**Output:**
```
         birthyear  children    hobby  weight
alice       1985       NaN   Biking      68
bob         1984       3.0  Dancing      83
charles     1992       0.0      NaN     112
```

## Operations on DataFrames

```python
grades_array = np.array([[8, 8, 9], [10, 9, 9], [4, 8, 2], [9, 10, 10]])
grades = pd.DataFrame(grades_array, columns=["sep", "oct", "nov"], index=["alice", "bob", "charles", "darwin"])
grades
```
**Output:**
```
         sep  oct  nov
alice     8    8    9
bob      10    9    9
charles   4    8    2
darwin    9   10   10
```

You can apply NumPy mathematical functions on a `DataFrame`: the function is applied to all values:

```python
np.sqrt(grades)
```

**Output:**
```
              sep       oct       nov
alice    2.828427  2.828427  3.000000
bob      3.162278  3.000000  3.000000
charles  2.000000  2.828427  1.414214
darwin   3.000000  3.162278  3.162278
```

```python
grades + 1
```

**Output:**
```
         sep  oct  nov
alice      9    9   10
bob       11   10   10
charles    5    9    3
darwin    10   11   11
```

Of course, the same is true for all other binary operations, including arithmetic (`*`,`/`,`**`...) and conditional (`>`, `==`...) operations:

```python
grades >= 5
```

**Output:**
```
         sep  oct  nov
alice    True  True  True
bob      True  True  True
charles  False  True  False
darwin   True  True  True
```

### Simple Aggregation

Aggregation operations, such as computing the `max`, the `sum` or the `mean` of a `DataFrame`, apply to each column, and you get back a `Series` object:

```python
grades.mean()
```

**Output:**
```
sep    7.75
oct    8.75
nov    7.50
dtype: float64
```

## Data Cleaning and Preparation

Data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.

Let's create a new DataFrame for this section with some missing values and duplicates:

```python
import pandas as pd
import numpy as np

data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Alice', 'Eva'],
    'Age': [25, 30, 35, 40, 25, 23],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'New York', 'Boston'],
    'Salary': [50000, 60000, 70000, 80000, 50000, np.nan]
}
df = pd.DataFrame(data)
```

### Handling Missing Data

Missing data is a common problem in real-world datasets. Pandas provides several methods to handle missing data, which are represented as `NaN` (Not a Number). 

```python
vals2 = np.array([1, np.nan, 3, 4])
vals2 
# Output: array([1., nan, 3., 4.])
1 + np.nan
# Output: nan
vals2.sum(), vals2.min(), vals2.max()
# Output: (nan, nan, nan)
np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)
# Output: (8.0, 1.0, 4.0)
```

In Pandas the `None` value is also considered as missing data but it is not the same as `NaN`. NaN and None both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:
```python
pd.Series([1, np.nan, 2, None])
```

**Output:**
```
0    1.0
1    NaN
2    2.0
3    NaN
dtype: float64
```

> **Note:** Pandas Handling of NAs by type
>
> | Type | Conversion when storing NAs | NA sentinel value |
> |------|-----|------|
> | `float` | No Change | `np.nan` |
> | `object` | No Change | `None` or `np.nan` |
> | `int` | Cast to `float64` | `np.nan` |
> | `bool` | Cast to `object` | `None` or `np.nan` |

**Example: Checking for missing data**

```python
# isnull() returns a DataFrame of booleans indicating if a value is missing
print(df.isnull())

# isnull().sum() gives the count of missing values in each column
print(df.isnull().sum())

# .notnull() returns a DataFrame of booleans indicating if a value is not missing
print(df.notnull())
```

**Example: Dropping missing data**

```python
# Drop rows with any missing values
df_dropped = df.dropna()
print(df_dropped)

# Drop columns with any missing values
df_dropped = df.dropna(axis="columns") # or df.dropna(axis=1)
print(df_dropped)

# Drop columns with all missing values
df_dropped = df.dropna(axis="columns", how="all") # or df.dropna(axis=1, how="all")
print(df_dropped)

# Drop rows that have less than 2 non-missing values
df_dropped = df.dropna(axis="rows", thresh=2) # or df.dropna(axis=0, thresh=2)
print(df_dropped)
```

**Example: Filling missing data**

```python
# Fill missing values with 0
df.fillna(0)

# Fill missing values by propagating the previous value forwards
df.fillna(method='ffill')

# Fill missing values by propagating the next value backwards
df.fillna(method='bfill')

# Fill missing salary with the mean salary
mean_salary = df['Salary'].mean()
df_filled = df.fillna({'Salary': mean_salary})
print(df_filled)
```

### Handling Duplicated Data

Duplicate rows can skew analysis. Pandas provides easy ways to find and remove them.

**Example: Identifying duplicate rows**

```python
# The duplicated() method returns a boolean Series indicating duplicate rows
print(df.duplicated())
```

**Example: Dropping duplicate rows**

```python
# The drop_duplicates() method removes duplicate rows
df_no_duplicates = df.drop_duplicates()
print(df_no_duplicates)
```

### Data Type Conversions

Sometimes data is not in the correct format. You can use the `astype()` method to convert data types.

**Example: Converting the 'Age' column to float**

```python
df['Age'] = df['Age'].astype(float)
print(df.dtypes)
```

